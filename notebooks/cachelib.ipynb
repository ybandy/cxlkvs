{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.cachelib_analyzer import *\n",
    "from utils.plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES_LIST = [1, 2, 4, 8, 16]\n",
    "NUM_THREADS_LIST = [8, 16]\n",
    "\n",
    "BASE_PATH = Path('..', 'cachelib', 'CacheLib-log')\n",
    "\n",
    "DRAM_LATENCY_LIST = [0]\n",
    "CXL_LATENCY_LIST = [500, 1000, 1500, 2000, 2500, 3000, 4000, 5000, 10000, 20000]\n",
    "MEM_LATENCY_LIST = DRAM_LATENCY_LIST + CXL_LATENCY_LIST\n",
    "\n",
    "GET_OP_RATIO = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRAM_LOGS = 'cachelib-benchmark-dram-%dcore-%dfiber-100000000-20000000000-1.0.stats'\n",
    "CXL_LOGS  = 'cachelib-benchmark-cxl-%dcore-%dfiber-100000000-20000000000-1.0.stats'\n",
    "\n",
    "# num_cores -> [8 threads, 16 threads]\n",
    "CXL_LATENCY_CHANGE_TIME_BASE = {\n",
    "    1: [441, 390],\n",
    "    2: [240, 250],\n",
    "    4: [150, 151],\n",
    "    8: [100, 100],\n",
    "    16: [60, 90],\n",
    "}\n",
    "CXL_LATENCY_CHANGE_TIME_STEP = 30\n",
    "    \n",
    "dram_stats_dict = get_stats(BASE_PATH, DRAM_LOGS, NUM_CORES_LIST, NUM_THREADS_LIST)\n",
    "cxl_stats_dict = get_stats(BASE_PATH, CXL_LOGS, NUM_CORES_LIST, NUM_THREADS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_throughput_dict = {}\n",
    "for num_cores in NUM_CORES_LIST:\n",
    "    cxl_latency_change_times = []\n",
    "    for i in range(len(CXL_LATENCY_LIST)):\n",
    "        d = {}\n",
    "        for j, num_threads in enumerate(NUM_THREADS_LIST):\n",
    "            t = CXL_LATENCY_CHANGE_TIME_BASE[num_cores][j] + CXL_LATENCY_CHANGE_TIME_STEP * i\n",
    "            d[num_threads] = t\n",
    "        cxl_latency_change_times.append(d)\n",
    "    max_t, _, _ = get_throughput_and_latency(dram_stats_dict[num_cores], cxl_stats_dict[num_cores],\n",
    "                                             cxl_latency_change_times, [])\n",
    "    max_throughput_dict[num_cores] = max_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IOS_PER_OP = 1.3\n",
    "\n",
    "SWITCH_TIME = 90\n",
    "NUM_PREFETCHES = 7\n",
    "NUM_CHASES = 5.8 / NUM_IOS_PER_OP\n",
    "MEMORY_TIME = 286.2 - 62\n",
    "IO_TIME_PRE = 2446.4 - 62\n",
    "IO_TIME_POST = 1293.7 - 62\n",
    "TITLE = 'CacheLib (100M items, single core)'\n",
    "NAME = 'cachelib100m_1core'\n",
    "NUM_CORES = 1\n",
    "\n",
    "latencies = []\n",
    "throughputs = []\n",
    "for lat, t in zip(MEM_LATENCY_LIST, max_throughput_dict[NUM_CORES]):\n",
    "    if(lat > 1000 and lat % 1000 == 500):\n",
    "        continue\n",
    "    elif(lat > 15000):\n",
    "        continue\n",
    "    else:\n",
    "        latencies.append(lat)\n",
    "        throughputs.append(t)\n",
    "\n",
    "_ = plot_with_models(latencies, throughputs,\n",
    "                     NUM_CHASES, MEMORY_TIME, IO_TIME_PRE, IO_TIME_POST,\n",
    "                     SWITCH_TIME, NUM_PREFETCHES, 'Aerospike/CacheLib', TITLE, NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throughput_dict = defaultdict(list)\n",
    "for i, lat in enumerate(MEM_LATENCY_LIST):\n",
    "    if(lat > 1000 and lat % 1000 == 500):\n",
    "        continue\n",
    "    elif(lat > 15000):\n",
    "        continue\n",
    "    else:\n",
    "        for num_cores in NUM_CORES_LIST:\n",
    "            throughput_dict[lat].append(max_throughput_dict[num_cores][i] / GET_OP_RATIO)\n",
    "\n",
    "with open('cachelib.json', 'w') as f:\n",
    "    json.dump(throughput_dict, f, indent=4)\n",
    "\n",
    "plot_core_scaling(NUM_CORES_LIST, throughput_dict, 'CacheLib (100M items)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES = 16\n",
    "throughputs = np.array(max_throughput_dict[NUM_CORES]) / GET_OP_RATIO\n",
    "plot_throughputs(MEM_LATENCY_LIST, throughputs, 2.1, 'C1',\n",
    "                 'CacheLib (100M items)', 'cachelib100m_16core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_throughput_over_time(stats_dict, title, time_ticks):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    vline_max = 0\n",
    "    for num_threads, stats in stats_dict.items():\n",
    "        ys = np.array(stats['cache_gets']) / 60 * 1e-6\n",
    "        plt.plot(stats['time'], ys, label='%d threads' % num_threads)\n",
    "        vline_max = max(vline_max, np.amax(ys))\n",
    "\n",
    "    if(time_ticks is not None):\n",
    "        plt.vlines(time_ticks, 0, vline_max, colors='gray')\n",
    "    plt.xlabel('Time [min]')\n",
    "    plt.ylabel('Throughput [M gets/sec]')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latency_over_time(stats_dict, percentile, title, time_ticks):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    vline_max = 0\n",
    "    for num_threads, stats in stats_dict.items():\n",
    "        ys = np.array(stats['find_p%d' % percentile]) * 1e-3\n",
    "        plt.plot(stats['time'], ys, label='%d threads' % num_threads)\n",
    "        vline_max = max(vline_max, np.amax(ys))\n",
    "\n",
    "    if(time_ticks is not None):\n",
    "        plt.vlines(time_ticks, 0, vline_max, colors='gray')\n",
    "    plt.xlabel('Time [min]')\n",
    "    plt.ylabel('P%d GET latency [usec]' % percentile)\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hit_ratio_over_time(stats_dict, tier, title, time_ticks):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    vline_max = 0\n",
    "    for num_threads, stats in stats_dict.items():\n",
    "        ys = np.array(stats['hit%s' % ('_' + tier if tier else '')])\n",
    "        plt.plot(stats['time'], ys, label='%d threads' % num_threads)\n",
    "        vline_max = max(vline_max, np.amax(ys))\n",
    "\n",
    "    if(time_ticks is not None):\n",
    "        plt.vlines(time_ticks, 0, vline_max, colors='gray')\n",
    "    plt.xlabel('Time [min]')\n",
    "    plt.ylabel('%s hit ratio [%%]' % (tier.upper() if tier else 'Total'))\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_over_time(stats_dict, title, percentile_list, time_ticks=None):\n",
    "    plot_throughput_over_time(stats_dict, title, time_ticks)\n",
    "    for p in percentile_list:\n",
    "        plot_latency_over_time(stats_dict, p, title, time_ticks)\n",
    "    plot_hit_ratio_over_time(stats_dict, '', title, time_ticks)\n",
    "    plot_hit_ratio_over_time(stats_dict, 'ram', title, time_ticks)\n",
    "    plot_hit_ratio_over_time(stats_dict, 'nvm', title, time_ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES = 16\n",
    "DRAM_LOGS = 'cachelib-benchmark-x4-dram-%dcore-%dfiber-400000000-20000000000-1.0.stats'\n",
    "CXL_LOGS  = 'cachelib-benchmark-x4-cxl-%dcore-%dfiber-400000000-20000000000-1.0.stats'\n",
    "\n",
    "PERCENTILE_LIST = [50, 90, 99]\n",
    "\n",
    "CXL_LATENCY_CHANGE_TIME_BASE = 320\n",
    "CXL_LATENCY_CHANGE_TIME_STEP = 30\n",
    "cxl_latency_change_times = []\n",
    "for i in range(len(CXL_LATENCY_LIST)):\n",
    "    t = CXL_LATENCY_CHANGE_TIME_BASE + CXL_LATENCY_CHANGE_TIME_STEP * i\n",
    "    d = {}\n",
    "    for num_threads in NUM_THREADS_LIST:\n",
    "        d[num_threads] = t\n",
    "    cxl_latency_change_times.append(d)    \n",
    "\n",
    "dram_stats_dict = get_stats(BASE_PATH, DRAM_LOGS, [NUM_CORES], NUM_THREADS_LIST)\n",
    "cxl_stats_dict = get_stats(BASE_PATH, CXL_LOGS, [NUM_CORES], NUM_THREADS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_over_time(dram_stats_dict[NUM_CORES], 'DRAM', PERCENTILE_LIST)\n",
    "plot_over_time(cxl_stats_dict[NUM_CORES], 'CXL', PERCENTILE_LIST,\n",
    "               [CXL_LATENCY_CHANGE_TIME_BASE + CXL_LATENCY_CHANGE_TIME_STEP * i for i in range(len(CXL_LATENCY_LIST))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, throughput_dict, get_latency_dict = get_throughput_and_latency(dram_stats_dict[NUM_CORES], cxl_stats_dict[NUM_CORES],\n",
    "                                                                  cxl_latency_change_times, PERCENTILE_LIST)\n",
    "\n",
    "NUM_THREADS = 8\n",
    "throughputs = np.array(throughput_dict[NUM_THREADS]) / GET_OP_RATIO\n",
    "plot_throughputs(MEM_LATENCY_LIST, throughputs, None, '#9400d3', 'CacheLib Operation Throughput (400M items)', 'cachelib400m_16core')\n",
    "\n",
    "plot_latencies(MEM_LATENCY_LIST, get_latency_dict[NUM_THREADS], PERCENTILE_LIST, 1e3,\n",
    "               'CacheLib Operation Latency (400M items)', 'cachelib400m_16core_latency')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
